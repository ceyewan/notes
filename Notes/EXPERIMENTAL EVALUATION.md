在本节中，我们进行了广泛的实验评估，以验证我们提出的攻击方法的实用性。我们使用了两个真实世界的数据集——**英文维基百科**和来自**国家生物技术信息中心（NCBI）** 的基因组数据集。关于这些数据集的描述可以在附录 B 中找到。实验结果表明，我们的攻击方法在扩展到大型数据集时，能够以合理的效率实现较高的成功率。我们的攻击代码已公开发布在 GitHub 上。

---

## 1 在简易英文维基百科上的实验

我们现在展示在简易英文维基百科数据集上进行攻击的实验结果。

### 1.1 **实验数据和辅助信息**

- **数据集划分**：
  从数据集中随机选择了**10 万篇维基百科页面**作为辅助数据集。从剩余的维基百科页面中，我们选择了**2 万到 10 万篇页面**（以 2 万为步长）作为目标数据集。

- **辅助信息的计算**：
  我们通过辅助数据集构建了一个**后缀树**。对于后缀树中的每条初始路径 \( \text{initpath} \)，我们将其出现的次数 \( \text{vol} \) 赋值为 \( \text{Aux(initpath)} = \text{vol} \)。
  - 每次运行攻击时，我们对 \( \text{Aux} \) 进行归一化：
    将其除以辅助数据集中文本的总长度，并乘以目标数据集中文本的总长度。
  - 对于目标数据集，我们同样构建后缀树并提取泄露信息。

---

### 1.2 **攻击参数**

我们现在讨论在简易英文维基百科上的攻击参数选择，首先回顾参数 \( \varepsilon \) 和 \( t \) 的作用。

- **参数 \( \varepsilon \)**：
  - 控制在初始候选集中为每个查询添加的子串数量。
  - **较大的 \( \varepsilon \)**：更有可能将正确的猜测包含在候选集中，但也会使候选集变得更大。
    - 缺点：候选集过大降低了模拟退火算法的效率，因为正确猜测更难从中被选出。

- **参数 \( t \)**：
  - 用于修剪候选集。
  - **较大的 \( t \)**：在修剪步骤中更宽松，因此正确猜测更可能保留在候选集中。
    - 缺点：较大的 \( t \) 无法有效减少候选集的大小，从而使模拟退火算法更难找到正确的猜测。

---

实验表明，通过调整参数 \( \varepsilon \) 和 \( t \)，可以在候选集大小和模拟退火效率之间找到平衡，从而提高攻击的成功率和效率。

### 1.3 考虑因素

综上所述，在选择参数时需要考虑两个相互冲突的因素：
1. **候选集的大小**：我们希望候选集尽可能小。在实验中，我们通过候选集大小的乘积来表示重建空间的大小（以 \(\log_{10}\) 为单位）。
2. **正确猜测被捕获的频率**：我们希望候选集中尽可能多地包含正确的猜测。在实验中，我们通过候选集中包含正确猜测的比例来表示命中率（Hit Rate）。

---

### 1.4 **实验结果**

- **参数选择范围**：
  - 在实验中，我们选择 \( \varepsilon \) 的范围为 3 到 7，\( t \) 的范围为 3 到 7（数据集包含 10 万个字符串和 1 万个查询）。
  - 此外，我们还进行了不使用修剪阈值 \( t \) 的实验。
  - 部分实验结果可在附录 C 的表 2 中查看。

---

### 1.5 **有趣的观察**

1. **重建空间的大小与 \( \varepsilon \) 的关系**：
   - 重建空间的大小并未随着 \( \varepsilon \) 的增加而单调减少。例如：
     - 当 \( \varepsilon = 3, t = 3 \) 时，重建空间的大小为 \( 10^{15039.46} \)；
     - 当 \( \varepsilon = 7, t = 3 \) 时，重建空间的大小为 \( 10^{7757.57} \)。
   - 这与直觉不同，但可以通过攻击中的修剪步骤来解释：
     - 当 \( \varepsilon \) 太小时，候选集中不包含足够多的正确猜测，导致修剪步骤的效果不佳，从而导致重建空间显著增大。

2. **修剪阈值 \( t \) 的有效性**：
   - 修剪阈值 \( t \) 在减少重建空间大小方面非常有效，并且不会显著牺牲命中率。例如：
     - 当 \( \varepsilon = 7 \) 且不进行修剪时，重建空间的大小为 \( 10^{10787.98} \)，命中率为 91.32%。
     - 通过使用 \( t = 3 \) 进行修剪，重建空间减少了 \( 10^{3030} \) 倍，而命中率仅下降了 0.42%。

---

在我们测试的所有参数组合中，\( \varepsilon = 7, t = 3 \) 在重建空间大小和命中率之间实现了最佳平衡。因此，这一设置被用于我们针对简易英文维基百科数据集的主要攻击实验。

### 1.6 查询生成

在我们的实验中，查询是随机生成的。对于每个查询，我们从目标数据集中随机选择一个维基百科页面。然后，我们在该维基百科页面内随机选择一个初始位置。接着，通过生成一个随机数（稍后指定）并将其加到初始位置上，确定最终位置。明文查询就是由随机选择的维基百科页面中初始位置和最终位置之间的子字符串。然而，明文查询在使用之前必须满足以下条件：

1. 查询必须具有特定的长度（稍后指定）。
2. 查询的响应量必须大于 100（这是为了避免使用错误提取的明文或不常见的短字符串作为查询；例如，在简易英文维基百科中关于 Alan Turing 的文章中，"== == Other" 就是一个例子）。
3. 查询中的字符只能包含英文字母、空格和连字符。

我们针对目标数据集生成了 10,000 个随机查询，目标数据集包含 20,000 到 80,000 个维基百科页面。对于包含 100,000 个维基百科页面的目标数据集，我们生成了 2,000 到 10,000 个随机查询。

---

### 1.7 评估指标

我们使用以下四个指标来衡量攻击的成功率：

- **唯一标记恢复率**：攻击正确恢复的唯一标记的百分比。例如，如果攻击正确恢复了标记 (1, 2, 3) 为 "elp"，但错误恢复了标记 (1, 2, 4) 为 "elt"，唯一标记恢复率将是 \(3/4 = 75\%\)，因为标记 1 和 2 只被计算一次。

- **带重复的标记恢复率**：攻击正确恢复的标记（包括重复）的百分比。例如，如果攻击正确恢复了标记 (1, 2, 3) 为 "elp"，但错误恢复了标记 (1, 2, 4) 为 "elt"，带重复的标记恢复率将是 \(5/6 = 75\%\)。该指标反映了每个查询中我们平均能正确猜测的字符百分比。

- **初始路径恢复率**：攻击正确恢复查询初始路径的百分比。这等同于我们能够正确猜测所有标记的查询百分比。例如，如果攻击正确恢复了标记 (1, 2, 3) 为 "elp"，但错误恢复了标记 (1, 2, 4) 为 "elt"，初始路径恢复率将是 \(1/2 = 50\%\)。

- **查询恢复率**：正确恢复查询的百分比。

### 1.8 攻击实验

我们针对 CS 方案进行了三组实验，并展示了实验结果。在这些实验中，我们研究了攻击在查询数量和字符串数量增加时的扩展能力。

---

**第一组实验**
在第一组实验中，我们以 100,000 个维基百科页面作为目标数据集，并使用 10,000 个查询生成泄露信息。查询的长度如表 1 所示。我们观察到，当允许长度为 1 和 2 的查询时，攻击效果最佳。这是因为长度为 1 和 2 的查询具有最大的查询响应量，因此更容易恢复。更有趣的是，这些短查询还可以提高较长查询的恢复率。具体而言，在我们的实验中，对于查询长度从 1 到 11 的情况，长度为 3 到 11 的查询的初始路径恢复率为 65.1%。这一结果比仅使用长度为 3 到 11 的查询时高出 13.1%。
这种提升的原因在于，长度为 1 和 2 的查询具有较小的候选集（因为它们的查询响应量最大，容易识别）。由于这些短查询与较长查询共享相同的初始路径（因此在我们的攻击中共享相同的标记），短查询较小的候选集也有助于减少较长查询的候选集大小，从而最终提高查询恢复率。

---

**第二组实验**
在第二组实验中，我们以 100,000 个维基百科页面作为目标数据集，并使用 2,000 到 10,000 个查询（长度在 3 到 11 之间）生成泄露信息。结果如图 2a 所示。
在所有实验中，唯一标记恢复率、初始路径恢复率和查询恢复率表现相似。当查询数量为 2,000 时，这些指标为 37%，当查询数量增加到 10,000 时，这些指标上升到 49%。这种现象可能是因为更多的查询增加了初始路径的交集，从而更好地优化了候选集。
带重复的标记恢复率显著高于其他指标。当查询数量为 10,000 时，带重复的标记恢复率超过了 70%。也就是说，对于每个查询，攻击者可以正确猜测 70% 的字符。

---

**第三组实验**
在最后一组实验中，我们以 20,000 到 100,000 个维基百科页面作为目标数据集，并使用 10,000 个查询（长度在 3 到 11 之间）生成泄露信息。结果如图 2b 所示。
我们没有观察到指标随字符串数量变化的显著趋势。这表明字符串数量并不是限制我们攻击的因素，20,000 个字符串已经足以使我们的攻击表现良好。

### 1.9 结果

![image.png](https://ceyewan.oss-cn-beijing.aliyuncs.com/typora/20250410165852.png)

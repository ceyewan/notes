面试官您好！我叫廖明秋，来自湖南衡阳，是武汉大学电子信息专业的在读硕士研究生，本科毕业于武汉大学。非常荣幸能够有机会参加今天的面试，期待与您交流。

我主要使用 Golang，熟悉 C++、Python，并且对微服务、云原生开发有浓厚的兴趣。具备扎实的计算机基础，尤其在分布式系统、数据库等方向有深入学习和实践。通过这些理论学习和实践研究，我不仅掌握了理论知识，还积累了丰富的工程实践经验。

在生活中，我热爱运动，长期坚持健身，培养了毅力和自律。同时，我积极参与科研竞赛和学校活动，提升了技术深度与团队协作能力，并通过技术博客分享学习心得和项目经验。

我的优势在于对技术原理的深入探索和较强的工程实践能力，同时具备强烈的自驱力和责任感。非常期待能有机会加入贵公司，并与优秀的团队共同成长。谢谢！

## 1 分布式微服务即时通讯系统

面试官您好！我设计的这个分布式微服务即时通讯系统采用了清晰的四层架构，分别是 **API 接入层**、**逻辑处理层**、**任务调度层** 和 **长连接层**。为了实现层与层之间的高效通信和解耦，我在 **逻辑处理层** 实现了 **LogicRPC** 服务，并在 **长连接层** 实现了 **ConnectRPC** 服务，它们都基于 **gRPC** 协议。

首先，**API 接入层** 是系统的入口，我选择了轻量级的 **Gin** 框架来构建。这一层主要负责接收用户的 HTTP 请求，例如登录、注册等。接收到请求后，API 接入层并不直接处理业务逻辑，而是通过 **gRPC** 调用后端的 **LogicRPC** 服务，将请求转发给 **逻辑处理层** 进行处理。

接下来是 **逻辑处理层**，这是系统的核心业务处理单元。它对外提供 **LogicRPC** 服务，内部主要负责用户认证、权限校验以及处理来自 **ConnectRPC** 的消息推等。为了高效地管理用户的在线状态，我使用了高性能的键值存储数据库 **Redis**。当接收到来自 API 接入层的消息后，**逻辑处理层** 的一个关键步骤是为每条消息生成一个全局唯一的分布式消息 ID，这对于后续的消息追踪和一致性至关重要。生成 ID 后，消息会被写入到高吞吐量的消息队列中，为后续的实时推送和持久化做准备。

为了保证消息的低延迟推送和可靠持久化，我引入了 **任务调度层**。这一层主要负责消费消息队列中的消息。我在这里实现了两种关键的处理逻辑，通过部署不同的消费者组来实现：

- **实时推送消费者组：** 这个组的消费者会实时地从消息队列中拉取消息，然后通过 **gRPC** 调用 **ConnectRPC** 服务，将消息投递到相应的 **长连接层** 实例，确保消息能够以极低的延迟送达在线用户。
- **消息持久化消费者组：** 这个组的消费者则专注于数据的可靠性，它们会异步地从消息队列中消费消息，并将消息内容持久化到 **MySQL** 数据库中，保证消息不会丢失。

最后是 **长连接层**，这一层直接面向用户，通过 **WebSocket** 协议与用户的客户端建立持久的双向通信连接。当用户成功登录后，客户端会与一个 **长连接层** 的实例建立 WebSocket 连接。**长连接层** 自身也扮演着客户端的角色，通过 **LogicRPC** 与 **逻辑处理层** 进行交互，例如上报用户的在线状态，以及接收需要通过 WebSocket 推送给用户的消息。**任务调度层** 在完成实时推送的逻辑后，实际上是将消息通过 **ConnectRPC** 投递到 **长连接层**，再由 **长连接层** 通过已建立的 WebSocket 连接将消息推送到用户的客户端。

为了提升系统的可扩展性和可靠性，我采用了 **etcd** 作为服务发现中心。所有的服务实例（包括逻辑处理层和长连接层）都会将自己的地址注册到 etcd 中，API 接入层和任务调度层则可以动态地从 etcd 中发现所需服务的地址，实现了服务的自动发现和负载均衡。此外，整个系统基于 **Docker Compose** 进行容器化部署，方便快速部署、管理和弹性伸缩。

**下面我将以一条单聊消息的发送流程为例，串联起这四个层面：**

面试官您好！我叫廖明秋，来自湖南衡阳，是武汉大学电子信息专业的在读硕士研究生，本科毕业于武汉大学。非常荣幸能够有机会参加今天的面试，感谢面试官的时间，期待与您交流。

我主要使用 Golang，熟悉 C++、Python，并且对微服务、云原生开发有浓厚的兴趣。具备扎实的计算机基础，尤其在分布式系统、数据库等方向有深入学习和实践。通过这些理论学习和实践研究，我不仅掌握了理论知识，还积累了丰富的工程实践经验。

在生活中，我热爱运动，长期坚持健身，培养了毅力和自律。同时，我积极参与科研竞赛和学校活动，提升了技术深度与团队协作能力，并通过技术博客分享学习心得和项目经验。

我的优势在于对技术原理的深入探索和较强的工程实践能力，同时具备强烈的自驱力和责任感。非常期待能有机会加入贵公司，并与优秀的团队共同成长。谢谢！
1. 用户在客户端发送一条消息，这条消息通过 HTTP 请求发送到 **API 接入层**。
2. **API 接入层** 接收到请求后，会调用 **LogicRPC** 服务（部署在 **逻辑处理层**），将消息内容、发送者和接收者信息传递给 **逻辑处理层**。
3. **逻辑处理层** 接收到消息后，首先进行必要的鉴权和业务逻辑处理，然后生成一个全局唯一的分布式消息 ID，并将该消息写入消息队列。同时，**逻辑处理层** 可能会通过查询 **Redis** 获取接收者的在线状态。
4. **任务调度层** 中的 **实时推送消费者组** 监听到新的消息后，会将其消费，并根据接收者的用户 ID，通过 **ConnectRPC** 调用相应的 **长连接层** 实例。
5. **长连接层** 接收到来自 **Task 层** 的推送请求后，会查找与接收者用户 ID 关联的 WebSocket 连接，并将消息通过该连接实时推送给用户的客户端。
6. 与此同时，**任务调度层** 中的 **消息持久化消费者组** 也会消费该消息，并将其异步地写入 **MySQL** 数据库进行持久化存储。

通过这样的分层设计和技术选型，我们的系统能够支持 **5W+ 的每秒查询率 (QPS)**，并保证消息投递延迟稳定在 **50 毫秒** 以内，同时具备秒级的故障恢复能力，能够高效地满足大规模用户的实时通讯需求。

Q：为什么要实现四层架构？你有什么考量？
1. 职责分离与模块化
2. 性能优化与高可用性
3. 开发与部署灵活
4. 后续扩展，如 Task 层增加消息批量处理、延迟投递、消息审计监控功能；Logic 层增加消息撤回、已读回执功能。

Q：如何确保消息唯一的投递？

- **使用 MurmurHash 哈希消息内容**，将 `userID + hash` 作为 Redis 的 key，并设置过期时间。
- **检查 Redis 中的重复 key**，如果存在，则判定为重复消息，拒绝投递。
- **生成分布式唯一 ID**，使用雪花算法为消息生成唯一 ID，确保消息在分布式系统中的唯一性。
- **投递到支持消息去重的消息队列**，如 Kafka 或 RabbitMQ 的幂等性生产者，配置消息的唯一 ID，防止重复投递。
- **增加幂等性检查**，在处理消息前，检查 MySQL 中是否已记录该消息 ID，确保消息只被处理一次。
- **结合 Redis 和消息队列**，通过双重机制确保消息的唯一投递和幂等性处理。

Q：有哪些应对高并发、提高容错率的办法？

- etcd 服务动态注册和发现，k8s 弹性伸缩
- 健康检查：心跳机制、HTTP 健康检查接口
- 熔断降级：当服务调用失败率达到阈值时，触发熔断，直接返回降级结果（默认值）
- 令牌桶限流：限制单位时间内的请求量，超出限制的请求被拒绝或排队。
- 负载均衡策略：一致性哈希、结合服务监控选择最佳服务实例来提供服务
- 服务监控、日志分析（普罗米修斯、ELK 等）：实时监控系统性能，分析日志定位问题。
- 消息队列：将操作异步化，减少请求响应时间，流量削峰。

**ELK** 是一个流行的日志管理和分析技术栈，由三个开源工具组成：

1. **Elasticsearch**：分布式搜索和分析引擎，用于存储和快速检索日志数据。
2. **Logstash**：数据收集和处理管道，用于接收、解析和转换日志数据。
3. **Kibana**：数据可视化工具，用于在 Web 界面中展示和分析日志数据。

Q：性能瓶颈分析？

1. 消息的反复序列化与反序列化
2. 内存、CPU 资源的竞争、IO 吞吐量
3. RPC 调用的性能瓶颈，流式调用、负载均衡

Q：项目难点？
1. 本项目的主要难点是同时维护服务级别和实例级别两种不同粒度的 RPC 连接抽象，在底层结合 etcd 实现用户无感的负载均衡和动态扩缩容的服务发现，用户只用获取一个单一的 gRPC 连接对象即可享受自动化的服务治理能力。第一套机制（ServiceDiscovery）通过自定义 etcd resolver 和 gRPC 负载均衡策略，将多实例的动态管理完全封装在连接对象内部，业务代码只需像使用普通 gRPC 连接一样发起调用，底层自动完成实例选择、连接复用和故障转移；第二套机制（ServiceInstanceConnManager）则通过维护实例级连接映射表，为需要定向通信的场景提供精准控制能力。两套机制共享 etcd 的监听通道但独立管理连接池，既通过服务抽象层实现了 " 面向服务 " 的透明调用，又通过实例管理层保留了 " 面向实例 " 的精细控制，形成互补的弹性架构。这种设计的关键在于通过 etcd 的实时事件通知机制保持两种抽象层状态的一致性，确保负载均衡连接和定点连接都能及时响应集群拓扑变化。从负载均衡器里面获取的是底层网络连接，代表与服务器的 TCP 连接；然后用户基于这个连接创建一个客户端接口，并使用。

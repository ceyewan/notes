## 1 大数据存储查询设计

**问题**：每天 TB 级玩家行为日志，需数据库存储并支持按时间段、玩家 ID 等条件快速查询。

**分析**：应对海量数据、高效索引和查询性能挑战。需分布式系统。

> [!NOTE] 数据库选型
> **MySQL**：基于 B+ 树，擅长读多写少场景的关系型数据库，不适合海量数据存储。
> **LevelDB**：基于 LSM 树的 KV 存储，写入性能高，但不支持 SQL 且查询能力有限。
> **InfluxDB**：时间序列数据库，写入快，时序查询高效，适合存储时间相关数据。
> **Elasticsearch**：基于倒排索引 + LSM 树，擅长全文检索和复杂分析。

**总体思路**：分层设计：数据采集、数据存储、索引与查询、扩展运维。

### 1.1 数据采集层

日志是实时产生的，需要低延迟、高吞吐量的写入通道，同时避免单点瓶颈。

- 使用分布式消息队列（如 Kafka）缓冲实时日志。
- 日志按（时间 + 玩家 ID）哈希分散到主题/分区。
- 日志包含：玩家 ID、时间戳、行为类型、附加数据（JSON）。

**优化**：批量写入、消息队列持久化。

### 1.2 数据存储层

TB 级数据需要分布式存储，结合时间序列和玩家 ID 的查询特点，选择合适的存储引擎。

- 选用分布式时间序列数据库，适合时间段查询。
- 数据按时间分区存储在分布式节点。
- 字段：时间戳（主键）、玩家 ID、行为数据。

**优化**：冷热分离（SSD、HDFS）、数据分片、预聚合、内存缓冲、异步批量写入。

### 1.3 索引与查询层

快速查询需要高效索引，时间段和玩家 ID 是主要条件，要针对这两种模式优化。

- 时间序列数据库自带时间索引，高效查询时间范围。
- 构建二级索引：分布式 KV 存储（Redis）维护玩家 ID 到时间戳的映射。

**优化**：缓存热点数据、异步更新索引。

### 1.4 拓展运维层

系统需支持数据增长和高可用，同时便于维护。

- **水平扩展**：存储和索引节点动态扩容，自动分配分片。
- **高可用**：数据多副本存储，分布在不同节点，容忍单点故障。
- **监控优化**：监控延迟、吞吐量，动态调整分片或资源。

**核心**：分而治之，多层次优化。

- **分而治之**：采集、存储、查询分层。
- **优化重点**：复合分区负载均衡，批量写入减压，索引加速查询。
- **结果**：高效支持 TB 级存储与亿级日活查询。

## 2 实时在线人数统计

**问题**：实时统计日活约一亿的游戏全服每分钟在线人数。

**分析**：高并发实时数据聚合与低延迟查询的挑战。

**总体思路**：利用流式处理引擎实时聚合玩家心跳数据，并使用分布式计数器进行统计。

### 2.1 数据采集层

- 游戏服务器发送玩家心跳数据（包含玩家 ID 和时间戳）至分布式消息队列（如 Kafka）。
- 心跳数据按玩家 ID 或服务器 ID 分区，提高并行处理能力。

**优化方向**：轻量级心跳协议，高吞吐写入保障。

### 2.2 数据聚合层

- 使用流式处理系统（如 Flink）实时消费 Kafka 中的心跳数据。
- **时间窗口划分**：Flink 按分钟划分时间窗口处理心跳数据流。
- **去重计数**：每个 Flink 任务可以使用 Redis 的 HyperLogLog 对窗口内的玩家 ID 进行近似去重计数，或使用精确去重方案（如 Set）。
- **分片聚合**：每个 Flink 任务负责一部分分区的数据聚合。
- **结果汇总**：将各 Flink 任务的统计结果发送至一个或多个全局计数器（如 Redis 集群）。

**优化方向**：选择合适的去重方案（精度 vs. 资源），状态管理，容错机制。

### 2.3 在线人数存储与查询层

- 使用高并发低延迟的分布式 KV 存储（如 Redis 集群）作为全局计数器，存储每分钟的在线人数。
- 后端服务直接读取 Redis 中的数据，对外提供实时在线人数查询接口。

**优化方向**：内存优化，读写分离，多级缓存。

**核心**：流式计算，分片聚合，分布式计数。

- **流式计算**：实时处理心跳数据流。
- **分片聚合**：分散计算压力，提高处理效率。
- **分布式计数**：提供高并发的计数服务。
- **结果**：实时、准确地统计高日活游戏的全服每分钟在线人数。

## 3 秒杀场景如何保证消息唯一性

如何确保消息唯一的投递？即考虑网络带来的重传（用分布式 ID），也考虑用户的多次误点击（用消息哈希去重）。最后结合幂等检查来处理。

- **使用 MurmurHash 哈希消息内容**，将 `userID + hash` 作为 Redis 的 key，并设置过期时间。
- **检查 Redis 中的重复 key**，如果存在，则判定为重复消息，拒绝投递。
- **生成分布式唯一 ID**，使用雪花算法为消息生成唯一 ID，确保消息在分布式系统中的唯一性。
- **投递到支持消息去重的消息队列**，如 Kafka 或 RabbitMQ 的幂等性生产者，配置消息的唯一 ID，防止重复投递。
- **增加幂等性检查**，在处理消息前，检查 MySQL 中是否已记录该消息 ID，确保消息只被处理一次。
- **结合 Redis 和消息队列**，通过双重机制确保消息的唯一投递和幂等性处理。

## 4 高并发，秒杀
![image.png](https://ceyewan.oss-cn-beijing.aliyuncs.com/typora/20250329131702.png)
左边部分主要偏向于编程应用，右边部分偏向于组件应用。
